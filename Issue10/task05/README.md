第五天

循环神经网络进阶；机器翻译及相关技术；注意力机制与Seq2seq模型

## 循环神经网络进阶

### GRU

RNN存在的问题：梯度较容易出现衰减或爆炸（BPTT）。

门控循环神经网络：捕捉时间序列中时间步距离较长的依赖关系。

* 重置门：有助于捕捉时间序列里短期的依赖关系。
* 更新门：有助于捕捉时间序列里长期的依赖关系。

GRU 很聪明的一点就在于，我们使用了同一个门控 [公式] 就同时可以进行遗忘和选择记忆（LSTM则要使用多个门控）

### LSTM

长短期记忆（Long short-term memory, LSTM）是一种特殊的RNN，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。
