第三天

LeNet；卷积神经网络进阶；批量归一化和残差网络

### LeNet

卷积神经网络就是含卷积层的网络。 LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。

这块没啥太多新东西。

### 高级的卷积神经网络

* LeNet 缺点

LeNet: 在大的真实数据集上的表现并不尽如人意。

1. 神经网络计算复杂。
2. 还没有大量深入研究参数初始化和非凸优化算法等诸多领域。

* 特征提取

机器学习的特征提取: 手工定义的特征提取函数

神经网络的特征提取：通过学习得到数据的多级表征，并逐级表示越来越抽象的概念或模式。

* AlexNet 特点

1. 8 层变换，其中有 5 层卷积和 2 层全连接隐藏层，以及 1 个全连接输出层。
2. 将 `sigmoid` 激活函数改成了更加简单的 `ReLU` 激活函数。
3. 用 `Dropout` 来控制全连接层的模型复杂度。
4. 引入数据增强，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。

* 卷积核替换

一个 5x5 的卷积核可以用两个 3x3 卷积核代替

两个 3x3 的卷积核的感受野的大小刚好是 5x5，且两个 3x3 的参数量少

* VGG

VGG：通过重复使用简单的基础块来构建深度模型。

Block: 数个相同的填充为1、窗口形状为的 3X3 卷积层,接上一个步幅为2、窗口形状为 2X2 的最大池化层。

注：**卷积层保持输入的高和宽不变，而池化层则对其减半**。
